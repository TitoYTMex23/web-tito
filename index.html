import requests
from bs4 import BeautifulSoup
import json
import urllib.parse
import time
import re

# --- TUS LLAVES ---
LLAVES = [
    "f7c4823bc30547ecaa903e4b8325317f", 
    "f29b1f90e6b84d90804553e1a57b49ff",
    "f812a1f7516144729bd00c31058846c8",
    "a38abdb3603149ea9cbb0d29ba9ad2be"
]
key_actual = 0
PAGINAS_TOTALES = 5 

def obtener_html(url):
    global key_actual
    url_encoded = urllib.parse.quote(url)
    while key_actual < len(LLAVES):
        api_url = f"https://api.scrapingant.com/v2/general?url={url_encoded}&x-api-key={LLAVES[key_actual]}&browser=true"
        try:
            r = requests.get(api_url, timeout=60)
            if r.status_code == 200: return r.text
            else: key_actual += 1
        except: return None
    return None

def limpiar_texto(texto):
    if not texto: return ""
    return texto.strip().replace("\n", " ").replace("\r", "")

def iniciar_cosecha():
    base_datos = []
    print(f"ðŸ’Ž INICIANDO SCRAPER V4 (FILTRO LIMPIEZA)")

    for p in range(1, PAGINAS_TOTALES + 1):
        url = f"https://www.gamestorrents.app/juegos-pc/page/{p}/"
        print(f"ðŸŒ Escaneando PÃ¡gina {p}...")
        html = obtener_html(url)
        if not html: break

        soup = BeautifulSoup(html, 'html.parser')
        juegos = soup.find_all('div', class_='post') 
        if not juegos: juegos = soup.find_all('a', title=True)

        for item in juegos:
            try:
                a_tag = item if item.name == 'a' else item.find('a')
                if not a_tag: continue
                
                href = a_tag.get('href', '')
                titulo_raw = a_tag.get('title', '')
                
                # --- FILTRO DE ORO ---
                # Ignoramos categorÃ­as y basura
                if "juegos torrents de" in titulo_raw.lower() or "page" in href:
                    continue

                if '/juegos-pc/' in href and len(titulo_raw) > 3:
                    t = titulo_raw.replace('Descargar ', '').replace(' para PC', '').replace(' por Torrent', '').split('(')[0].strip()
                    print(f"   > Procesando: {t}...", end="\r")
                    
                    sub_html = obtener_html(href)
                    datos = {'imagen': '', 'peso': 'PC', 'desc': 'Disponible en TITOMX.'}
                    
                    if sub_html:
                        sub_soup = BeautifulSoup(sub_html, 'html.parser')
                        og = sub_soup.find("meta", property="og:image")
                        if og: datos['imagen'] = og["content"]
                        
                        texto = sub_soup.get_text()
                        match = re.search(r'(?:TamaÃ±o|Size|Peso)[:\s]+([\d\.]+\s*[GM]Bs?)', texto, re.IGNORECASE)
                        if match: datos['peso'] = match.group(1)
                        
                        og_desc = sub_soup.find("meta", property="og:description")
                        if og_desc: datos['desc'] = limpiar_texto(og_desc["content"])[:300] + "..."

                    # Si no hay imagen, usamos placeholder
                    if not datos['imagen']: datos['imagen'] = "https://via.placeholder.com/150"

                    base_datos.append({
                        "titulo": t,
                        "imagen": datos['imagen'],
                        "info": f"TITOMX.STORE | {datos['peso']}",
                        "desc": datos['desc'],
                        "comando": f"/game {t}"
                    })
            except: continue

    with open("games.js", "w", encoding="utf-8") as f:
        f.write("const DATABASE_JUEGOS = ")
        json.dump(base_datos, f, ensure_ascii=False, indent=2)
        f.write(";")
    print("\nâœ… LISTO. Sube games.js a GitHub.")

if __name__ == "__main__":
    iniciar_cosecha()
